{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Cleaning/Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to clean the notebooks of missing values, and impute additional features which I can calculate from the box score. These features I think will be useful for capturing additional variance in my data. In addition, I merge the game data with the corresponding gambling lines in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_handles_dict = {'Toronto Raptors': 'TOR',\n",
    "                     'Boston Celtics': 'BOS',\n",
    "                     'Philadelphia 76ers': 'PHI',\n",
    "                     'Cleveland Cavaliers': 'CLE',\n",
    "                     'Indiana Pacers': 'IND',\n",
    "                     'Miami Heat': 'MIA',\n",
    "                     'Milwaukee Bucks': 'MIL',\n",
    "                     'Washington Wizards': 'WAS',\n",
    "                     'Detroit Pistons': 'DET',\n",
    "                     #'Charlotte Hornets': 'CHO',\n",
    "                     #'Charlotte Bobcats': 'CHA',\n",
    "                     'New York Knicks': 'NYK',\n",
    "                     'Brooklyn Nets': 'BRK',\n",
    "                     'Chicago Bulls': 'CHI',\n",
    "                     'Orlando Magic': 'ORL',\n",
    "                     'Atlanta Hawks': 'ATL',\n",
    "                     'Houston Rockets': 'HOU',\n",
    "                     'Golden State Warriors': 'GSW',\n",
    "                     'Portland Trail Blazers': 'POR',\n",
    "                     'Oklahoma City Thunder': 'OKC',\n",
    "                     'Utah Jazz': 'UTA',\n",
    "                     'New Orleans Pelicans': 'NOP',\n",
    "                     'San Antonio Spurs': 'SAS',\n",
    "                     'Minnesota Timberwolves': 'MIN',\n",
    "                     'Denver Nuggets': 'DEN',\n",
    "                     'L.A. Clippers': 'LAC',\n",
    "                     'L.A. Lakers': 'LAL',\n",
    "                     'Sacramento Kings': 'SAC',\n",
    "                     'Dallas Mavericks': 'DAL',\n",
    "                     'Memphis Grizzlies': 'MEM',\n",
    "                     'Phoenix Suns': 'PHO'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataframe_loader:\n",
    "- loads data from repository into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_loader(years_games):\n",
    "    years_stats = []\n",
    "    for game in years_games:\n",
    "        with open(f'{game}') as g:\n",
    "            years_stats.append(json.load(g))\n",
    "    all_games_year = [team for game_list in years_stats for game in game_list for team in game]\n",
    "    df_year = pd.DataFrame(all_games_year, columns=['gid', 'team_slug', 'away_home', 'mp', 'fg', 'fga',\n",
    "                                                    'fg%', '3p', '3pa', '3p%', 'ft', 'fta', 'ft%', 'orb',\n",
    "                                                    'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts'])\n",
    "    return df_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_2014 = !ls ../raw_data_files/*_2014.json\n",
    "gl_2015 = !ls ../raw_data_files/*_2015.json\n",
    "gl_2016 = !ls ../raw_data_files/*_2016.json\n",
    "gl_2017 = !ls ../raw_data_files/*_2017.json\n",
    "gl_2018 = !ls ../raw_data_files/*_2018.json\n",
    "\n",
    "df_2014 = dataframe_loader(gl_2014)\n",
    "df_2015 = dataframe_loader(gl_2015)\n",
    "df_2016 = dataframe_loader(gl_2016)\n",
    "df_2017 = dataframe_loader(gl_2017)\n",
    "df_2018 = dataframe_loader(gl_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_2014.append([df_2015, df_2016, df_2017, df_2018], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['date'] = df_all['gid'].map(lambda x: x[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../raw_data_files/all_gambling_lines.json') as g:\n",
    "     all_lines = json.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lines = pd.DataFrame(data=all_lines[0])\n",
    "for day_line in all_lines[1:]:\n",
    "    df_lines = df_lines.append(day_line, ignore_index=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing this cell to make corrections to the lines for data points where I have to manually impute the line because the line was missing from the website I scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lines.loc[384, 2] = '-1 -105'\n",
    "df_lines.loc[385, 2] = '194.5 -105'\n",
    "df_lines.loc[2466, 2] = '203.5 -105'\n",
    "df_lines.loc[2467, 2] = '-1 -105'\n",
    "df_lines.loc[5677, 2] = '0 -105'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing this cell to append missing lines to my Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_lines = pd.DataFrame([['20150306', 'Miami', '+6 -110'], \n",
    "                             ['20150306', 'Washington','193 -110']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lines = df_lines.append(missing_lines, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lines.rename({0:'date', 1:'team', 2:'full_line'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lines['team_slug'] = df_lines['team']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wrote this cell to get the team_slug from a team name. With Charlotte, because there is a split between the slugs based on time, I set all of the 2014 season's games to the Charlotte Bobcats slug, and every seasons' games following to have the clug of the Charlotte Hornets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, team in enumerate(df_lines['team']):\n",
    "    if team == \"Charlotte\":\n",
    "        if int(df_lines['date'][i]) < 20141001:\n",
    "            df_lines['team_slug'][i] = 'CHA'\n",
    "        else:\n",
    "            df_lines['team_slug'][i] = 'CHO'\n",
    "    else:\n",
    "        for key in team_handles_dict:     \n",
    "            if team in key:\n",
    "                df_lines['team_slug'][i] = team_handles_dict[key]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lines['gid'] = df_lines['date'] + '0' + df_lines['team_slug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, entry in enumerate(df_lines['gid']):\n",
    "    if i % 2 == 0:\n",
    "        df_lines['gid'][i] = df_lines['gid'][i+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below I merge my game data and my gambling lines data, using both team slug and game ID as the features to join on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_all, df_lines, how='inner', on=['gid', 'team_slug'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_away_dict = {'away': 0, 'home': 1}\n",
    "\n",
    "df['home'] = df.away_home.map(lambda x: home_away_dict[x]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['betting_line'] = df['full_line'].map(lambda x: str.split(x)[0])\n",
    "df['bet_terms'] = df['full_line'].map(lambda x: str.split(x)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells are Regex equations I made to remove the 1/2 symbol from the betting lines, and impute .5 in its place. I did this because the 1/2 symbol was recognized as a special character and not a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = re.compile(r'[^0-9+-]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, entry in enumerate(df['betting_line']):\n",
    "    if p.findall(entry):\n",
    "        df.loc[i, 'betting_line'] = entry.replace(p.findall(entry)[0], '.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime([x[0:4] + '-' + x[4:6] + '-' + x[6:8] for x in df['date_x']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['date_x', 'team', 'mp', 'away_home', 'full_line', 'date_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['team_slug', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['fg', 'fga', '3p', '3pa', 'ft', 'fta', \n",
    "           'orb', 'drb', 'trb', 'ast', 'stl', \n",
    "           'blk', 'tov', 'pf', 'pts']] = df[['fg', 'fga', '3p', '3pa', 'ft', 'fta', \n",
    "           'orb', 'drb', 'trb', 'ast', 'stl', \n",
    "           'blk', 'tov', 'pf', 'pts']].astype('int64', copy=True)\n",
    "\n",
    "df[['fg%', '3p%', 'ft%', \n",
    "    'betting_line', 'bet_terms']] = df[['fg%', '3p%', \n",
    "                                        'ft%', 'betting_line', 'bet_terms']].astype('float64', copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By merging the dataframe on itself and then removing rows where the merge imputed the same information twice on one row, I am able to return a dataframe which represents a game on one row, as both the target team's box score and their opponent's box score. Every game is represented twice, once for each team participating in the game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doubled_df = df.merge(df, on='gid',  suffixes=['_1', '_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = doubled_df[doubled_df['team_slug_1'] != doubled_df['team_slug_2']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation for Offensive Rating: \n",
    "\n",
    "Offensive Rating = 100 x Pts / (0.5 * ((Tm FGA + 0.4 * Tm FTA - 1.07 * (Tm ORB / (Tm ORB + Opp DRB)) * (Tm FGA - Tm FG) + Tm TOV) + (Opp FGA + 0.4 * Opp FTA - 1.07 * (Opp ORB / (Opp ORB + Tm DRB)) * (Opp FGA - Opp FG) + Opp TOV)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['off_rating_1'] = merged_df.apply((lambda x: 100 * x['pts_1'] / \n",
    "                (0.5*((x['fga_1'] + 0.4*(x['fta_1']) - 1.07*(x['orb_1'] / (x['orb_1'] + x['drb_2']))\n",
    "                 * (x['fga_1'] - x['fg_1']) + x['tov_1']) +\n",
    "                (x['fga_2'] + 0.4*(x['fta_2']) - 1.07*(x['orb_2'] / (x['orb_2'] + x['drb_1']))\n",
    "                 * (x['fga_2'] - x['fg_2']) + x['tov_2'])))), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['off_rating_2'] = merged_df.apply((lambda x: 100 * x['pts_2'] / \n",
    "                (0.5*((x['fga_2'] + 0.4*(x['fta_2']) - 1.07*(x['orb_2'] / (x['orb_2'] + x['drb_1']))\n",
    "                 * (x['fga_2'] - x['fg_2']) + x['tov_2']) +\n",
    "                (x['fga_1'] + 0.4*(x['fta_1']) - 1.07*(x['orb_1'] / (x['orb_1'] + x['drb_2']))\n",
    "                 * (x['fga_1'] - x['fg_1']) + x['tov_1'])))), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['off_rating_1'] = round(merged_df['off_rating_1'], 2)\n",
    "merged_df['off_rating_2'] = round(merged_df['off_rating_2'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_under_list = []\n",
    "for i, x in enumerate(merged_df['betting_line_1']):\n",
    "    if x > merged_df['betting_line_2'][i]:\n",
    "        over_under_list.append(x)\n",
    "    else:\n",
    "        over_under_list.append(merged_df['betting_line_2'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['over_under'] = pd.Series(over_under_list, merged_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, value in enumerate(merged_df['betting_line_1']):\n",
    "    if merged_df.loc[i, 'betting_line_1'] > 0:\n",
    "        merged_df.loc[i, 'betting_line_1'] = merged_df.loc[i, 'betting_line_2'] * -1\n",
    "    else:\n",
    "        merged_df.loc[i, 'betting_line_2'] = merged_df.loc[i, 'betting_line_1'] * -1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.set_index('date_2', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.drop(['bet_terms_1', 'bet_terms_2', 'date_1', 'index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('clean_nba_betting_dataframe_full.csv', columns=merged_df.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
