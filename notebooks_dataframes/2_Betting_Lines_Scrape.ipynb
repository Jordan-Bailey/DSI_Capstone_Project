{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Betting Lines Scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook's primary function is to scrape the website sportsbookreview.com for gambling lines (both totals and spreads) corresponding to each game in the 2014-2018 NBA seasons. I took the data previously collected from basketball-reference.com, and used the dates when games were played to query the website and collect each day's betting lines. I then put this historical data in a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataframe_loader: \n",
    "\n",
    "- returns a dataframe containing one years games from a list of jsons containing each teams games for the season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_loader(years_games):\n",
    "    years_stats = []\n",
    "    for game in years_games:\n",
    "        with open(f'{game}') as g:\n",
    "            years_stats.append(json.load(g))\n",
    "    all_games_year = [team for game_list in years_stats for game in game_list for team in game]\n",
    "    df_year = pd.DataFrame(all_games_year)\n",
    "    return df_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_2014 = !ls ../raw_data_files/*_2014.json\n",
    "gl_2015 = !ls ../raw_data_files/*_2015.json\n",
    "gl_2016 = !ls ../raw_data_files/*_2016.json\n",
    "gl_2017 = !ls ../raw_data_files/*_2017.json\n",
    "gl_2018 = !ls ../raw_data_files/*_2018.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014 = dataframe_loader(gl_2014)\n",
    "df_2015 = dataframe_loader(gl_2015)\n",
    "df_2016 = dataframe_loader(gl_2016)\n",
    "df_2017 = dataframe_loader(gl_2017)\n",
    "df_2018 = dataframe_loader(gl_2018)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_2014.append([df_2015, df_2016, df_2017, df_2018], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['date'] = df_all[0].map(lambda x: x[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = [date for date in df_all['date'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(date_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get_betting_lines: \n",
    "- Function takes in a date, queries sportsbookreview.com for the corresponding page, and returns the day's betting lines labeled by team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_betting_lines(date):\n",
    "    info_list = []\n",
    "    betting_page = requests.get(f'https://www.sportsbookreview.com/betting-odds/nba-basketball/merged/?date={date}')\n",
    "    time.sleep(2)\n",
    "    betting_page = BeautifulSoup(betting_page.text, 'html.parser')\n",
    "    teams_list = []\n",
    "    for row in betting_page.find_all('div', {'class': 'eventLine-value'}):\n",
    "        teams_list.append(row.text)\n",
    "    betting_lines = []\n",
    "    for item in betting_page.find_all('div', {'class': 'event-holder holder-complete'}):\n",
    "        for line in item.find('div', {'class': 'el-div eventLine-book'}):\n",
    "            betting_lines.append(line.text)\n",
    "    betting_lines = [line.replace('\\xa0', ' ') for line in betting_lines]\n",
    "    \n",
    "    date_list = [date for item in betting_lines]\n",
    "    zipped_teams_lines = zip(date_list, teams_list, betting_lines)\n",
    "    return list(zipped_teams_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines = []\n",
    "for date in date_list:\n",
    "    all_lines.append(get_betting_lines(date))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_gambling_lines.json', 'w') as f:\n",
    "    json.dump(all_lines, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
